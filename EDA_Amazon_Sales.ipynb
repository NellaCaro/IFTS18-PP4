{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a57a3d6",
   "metadata": {},
   "source": [
    "# EDA: Amazon Sale Report\n",
    "\n",
    "Este notebook realiza la limpieza, análisis descriptivo, visualización y conclusiones sobre el dataset **Amazon Sale Report.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración general\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# Carga de datos\n",
    "df = pd.read_csv('Amazon Sale Report.csv', low_memory=False)\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae187bd3",
   "metadata": {},
   "source": [
    "## Exploración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5eed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información de columnas y nulos\n",
    "display(df.info())\n",
    "df.isna().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace14375",
   "metadata": {},
   "source": [
    "## Limpieza y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c623c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia de trabajo\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Estandarizar nombres de columnas (strip + reemplazar dobles espacios)\n",
    "df_clean.columns = (\n",
    "    df_clean.columns.str.strip()\n",
    "                    .str.replace('\\s+', ' ', regex=True)\n",
    ")\n",
    "\n",
    "# Eliminar columnas irrelevantes si existen\n",
    "cols_drop = [c for c in ['Unnamed: 22', 'promotion-ids'] if c in df_clean.columns]\n",
    "if cols_drop:\n",
    "    df_clean = df_clean.drop(columns=cols_drop)\n",
    "\n",
    "# Parseo de fecha\n",
    "# El formato del CSV se ve como MM-DD-YY (ej: 04-30-22).\n",
    "if 'Date' in df_clean.columns:\n",
    "    df_clean['Date'] = pd.to_datetime(df_clean['Date'], format='%m-%d-%y', errors='coerce')\n",
    "\n",
    "# Coerción de tipos numéricos con seguridad (usa dtypes anulables de pandas)\n",
    "for col in ['Qty', 'Amount', 'ship-postal-code']:\n",
    "    if col in df_clean.columns:\n",
    "        # Intentar convertir a número\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "        # Para códigos postales y Qty preferimos enteros anulables si aplica\n",
    "        if col in ['Qty', 'ship-postal-code']:\n",
    "            df_clean[col] = df_clean[col].astype('Int64')\n",
    "\n",
    "# Trim de strings en columnas categóricas típicas\n",
    "for col in ['Status', 'Fulfilment', 'Sales Channel ', 'ship-service-level', 'Style', 'SKU',\n",
    "            'Category', 'Size', 'ASIN', 'Courier Status', 'currency', 'ship-city',\n",
    "            'ship-state', 'ship-country', 'fulfilled-by']:\n",
    "    if col in df_clean.columns and df_clean[col].dtype == 'object':\n",
    "        df_clean[col] = df_clean[col].astype(str).str.strip()\n",
    "\n",
    "# Normalización de Ship Country, Ship State y Ship City\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def clean_location(s):\n",
    "    if pd.isna(s):\n",
    "        return s\n",
    "    s = str(s).strip(\" ,.;:-_/\\\\'\\\"()[]{}\")\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = re.sub(r\",\\s*\", \", \", s)\n",
    "    s = s.lstrip(\", \").strip()\n",
    "    if re.fullmatch(r\"\\d+(\\.\\d+)?\", s) or len(s) <= 1:\n",
    "        return np.nan\n",
    "    return s.title()\n",
    "\n",
    "for col in ['ship-city', 'ship-state', 'ship-country']:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col] = df_clean[col].apply(clean_location)\n",
    "\n",
    "# Marca de nulos en Amount\n",
    "if 'Amount' in df_clean.columns:\n",
    "    print(\"Nulos en Amount:\", df_clean['Amount'].isna().sum())\n",
    "    df_clean['Amount_is_null'] = df_clean['Amount'].isna()\n",
    "\n",
    "# Duplicados (mantenemos la primera ocurrencia)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "\n",
    "print('Shape después de limpieza:', df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b8b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar y asegurar la columna Date para Tableau\n",
    "# Parsear con formato explícito y contar fallas\n",
    "if 'Date' in df_clean.columns:\n",
    "    dt = pd.to_datetime(df_clean['Date'], format='%m-%d-%y', errors='coerce')\n",
    "    print(\"Filas con Date inválida (NaT) tras el parseo:\", int(dt.isna().sum()))\n",
    "    print(\"Rango de fechas (min, max):\", dt.min(), dt.max())\n",
    "    df_clean['Date'] = dt\n",
    "\n",
    "    # Crear columnas para Tableau\n",
    "    df_clean['Year_num']   = df_clean['Date'].dt.year\n",
    "    df_clean['Month_str']  = df_clean['Date'].dt.to_period('M').astype(str)  # '2022-04'\n",
    "    df_clean['Day_num']    = df_clean['Date'].dt.day\n",
    "    df_clean['Date_str']   = df_clean['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Export-friendly: formatear Date como string ISO (yyyy-mm-dd)\n",
    "    df_clean['Date_str'] = df_clean['Date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e3a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar export para Tableau\n",
    "import csv\n",
    "\n",
    "# Asegurar nombres únicos\n",
    "rename_map = {\n",
    "    'year': 'Year_num',\n",
    "    'Year': 'Year_num',\n",
    "    'month': 'Month_str',\n",
    "    'Month': 'Month_str',\n",
    "    'day': 'Day_num',\n",
    "    'Day': 'Day_num',\n",
    "}\n",
    "df_clean = df_clean.rename(columns={k:v for k,v in rename_map.items() if k in df_clean.columns})\n",
    "\n",
    "# Chequeo de unicidad\n",
    "n_cols = len(df_clean.columns)\n",
    "n_unique = df_clean.columns.nunique()\n",
    "print(f\"Columnas totales: {n_cols} | únicas: {n_unique}\")\n",
    "assert n_cols == n_unique, \"Hay nombres de columna repetidos. Revisa rename_map o renombra manualmente.\"\n",
    "\n",
    "# Ordenar columnas (opcional)\n",
    "cols_order = list(df_clean.columns)  \n",
    "df_out = df_clean[cols_order].copy()\n",
    "\n",
    "# Asegurar formatos “Tableau-friendly”\n",
    "# - Fecha ISO como string\n",
    "if 'Date' in df_out.columns:\n",
    "    df_out['Date_str'] = df_out['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Exportar en **TSV** (TAB) para evitar conflictos de coma/punto y coma\n",
    "tsv_path = \"Amazon_Sale_Report_CLEAN_TABLEAU.tsv\"\n",
    "df_out.to_csv(\n",
    "    tsv_path,\n",
    "    sep='\\t',               # DELIMITADOR TAB\n",
    "    index=False,\n",
    "    encoding='utf-8',\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    line_terminator='\\n'\n",
    ")\n",
    "print(\"Exportado:\", tsv_path)\n",
    "\n",
    "# Export 'sanity' con SOLO cabecera para testear columnas en Tableau\n",
    "header_only = \"HEADER_ONLY_TABLEAU.tsv\"\n",
    "pd.DataFrame(columns=df_out.columns).to_csv(\n",
    "    header_only, sep='\\t', index=False, encoding='utf-8'\n",
    ")\n",
    "print(\"Cabecera exportada:\", header_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Info post-limpieza:')\n",
    "display(df_clean.info())\n",
    "print('\\nNulos post-limpieza (top 20):')\n",
    "df_clean.isna().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a0128",
   "metadata": {},
   "source": [
    "## Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69946f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numéricas\n",
    "desc_num = df_clean.select_dtypes(include=['number']).describe().T\n",
    "display(desc_num)\n",
    "\n",
    "# Frecuencias categóricas clave\n",
    "for col in ['Status', 'Category', 'Fulfilment', 'Sales Channel ', 'ship-city', 'ship-state']:\n",
    "    if col in df_clean.columns:\n",
    "        print(f'\\nTop valores en {col}:')\n",
    "        display(df_clean[col].value_counts(dropna=False).head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e0482c",
   "metadata": {},
   "source": [
    "## Análisis temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a1480",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date' in df_clean.columns:\n",
    "    df_clean['year'] = df_clean['Date'].dt.year\n",
    "    df_clean['month'] = df_clean['Date'].dt.to_period('M').astype(str)\n",
    "    df_clean['day'] = df_clean['Date'].dt.date\n",
    "\n",
    "    # Ingresos diarios\n",
    "    if {'Date','Amount'}.issubset(df_clean.columns):\n",
    "        daily_rev = df_clean.groupby('Date', dropna=True)['Amount'].sum().sort_index()\n",
    "        display(daily_rev.head())\n",
    "\n",
    "        # Gráfico - usar matplotlib y no fijar colores específicos\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(daily_rev.index, daily_rev.values)\n",
    "        plt.title('Ingresos diarios')\n",
    "        plt.xlabel('Fecha'); plt.ylabel('Monto')\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Ingresos por mes\n",
    "    if {'month','Amount'}.issubset(df_clean.columns):\n",
    "        monthly_rev = df_clean.groupby('month')['Amount'].sum().sort_index()\n",
    "        display(monthly_rev.tail())\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(monthly_rev.index, monthly_rev.values)\n",
    "        plt.title('Ingresos mensuales')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.xlabel('Mes'); plt.ylabel('Monto')\n",
    "        plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb45bdc",
   "metadata": {},
   "source": [
    "## Patrones por categoría, estado y fulfilment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_top(series, title, top=10):\n",
    "    vc = series.value_counts().head(top)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.bar(vc.index.astype(str), vc.values)\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'Status' in df_clean.columns:\n",
    "    bar_top(df_clean['Status'], 'Pedidos por estado')\n",
    "if 'Category' in df_clean.columns:\n",
    "    bar_top(df_clean['Category'], 'Pedidos por categoría')\n",
    "if 'Fulfilment' in df_clean.columns:\n",
    "    bar_top(df_clean['Fulfilment'], 'Pedidos por tipo de fulfilment')\n",
    "if 'ship-city' in df_clean.columns:\n",
    "    bar_top(df_clean['ship-city'], 'Top 10 ciudades con más pedidos', top=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3a0061",
   "metadata": {},
   "source": [
    "## Métricas clave de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}\n",
    "if 'Amount' in df_clean.columns:\n",
    "    metrics['Ingresos totales'] = float(np.nansum(df_clean['Amount']))\n",
    "if {'Qty','Amount'}.issubset(df_clean.columns):\n",
    "    metrics['Ticket promedio (Amount por fila válida)'] = float(np.nanmean(df_clean.loc[df_clean['Amount'].notna(), 'Amount']))\n",
    "if 'Status' in df_clean.columns:\n",
    "    total_orders = len(df_clean)\n",
    "    cancelled = int((df_clean['Status'] == 'Cancelled').sum())\n",
    "    metrics['% Cancelados'] = round(100*cancelled/total_orders, 2) if total_orders else np.nan\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00765344",
   "metadata": {},
   "source": [
    "## Insights y observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561bf132",
   "metadata": {},
   "source": [
    "- **Calidad de datos**: Se detectaron valores nulos en columnas clave (por ejemplo, códigos postales). Se usaron dtypes anulables (`Int64`) para conservar filas sin forzar imputaciones.\n",
    "- **Temporalidad**: La columna `Date` fue parseada con formato `MM-DD-YY` y `errors='coerce'` para robustez.\n",
    "- **Ingresos**: Revisar picos y caídas en el gráfico de ingresos diarios/mensuales para asociarlos a campañas o eventos.\n",
    "- **Cancelaciones**: Ver el porcentaje de pedidos `Cancelled` y cruzarlo con `Fulfilment` o `ship-city` para encontrar focos de mejora logística.\n",
    "- **Top categorías/ciudades**: Observar qué categorías y ciudades concentran más pedidos para priorizar inventario y campañas.\n",
    "- **Próximos pasos**: Segmentar por `Courier Status`, analizar `Qty x Amount`, y detectar outliers en montos/qty; agregar mapa si se dispone de coordenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d11885",
   "metadata": {},
   "source": [
    "## Export del dataset limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f8da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el dataset limpio para importar en Tableau\n",
    "df_clean['Amount'] = df_clean['Amount'].round(2) # asegurar formato correcto\n",
    "df_clean.to_csv(\"Amazon_Sale_Report_CLEAN.csv\", index=False, sep=';', decimal=',') # Usar ; como separador y , como decimal\n",
    "'Archivo exportado: Amazon_Sale_Report_CLEAN.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
